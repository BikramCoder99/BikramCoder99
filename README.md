# About Me:
## Bikram Mondal  
[![LinkedIn](https://img.shields.io/badge/LinkedIn-%230077B5.svg?logo=linkedin&logoColor=white)](https://www.linkedin.com/in/bikram191199)  
[![Email](https://img.shields.io/badge/Email-D14836?logo=gmail&logoColor=white)](mailto:bikrammondal.tech@gmail.com)

I am a **Big Data Engineer and System Engineer at Tata Consultancy Services (TCS)** with **4.7+ years of hands-on industry experience** in designing, building, and optimizing scalable data engineering solutions on the **Azure cloud platform**. My work focuses on delivering **reliable, high-performance data pipelines** that enable enterprise analytics and data-driven decision-making.  
<br><br>

My core expertise lies in **Big Data and cloud-based ETL engineering**, where I work extensively with **Apache Spark, Azure Databricks, Azure Data Factory, and Azure Data Lake Storage (ADLS Gen2)** to process large-scale structured and semi-structured datasets. I have successfully executed **end-to-end data migrations from Mainframe and Teradata to Azure**, ensuring data accuracy, lineage, and quality compliance.  
<br><br>

I am highly proficient in **PySpark, Python, Spark SQL, SQL, Scala**, and distributed data processing frameworks. My experience includes developing **reusable SQL stored procedures**, **JSON-based curation frameworks**, and **PySpark applications** for data cleansing, validation, transformation, aggregation, and partitioning. I have automated complete ETL lifecycles using **parameterized ADF pipelines, triggers, and Databricks notebook orchestration**, improving pipeline reliability and reducing operational overhead.  
<br><br>

Across projects such as **Trade Price & Promotion Management (TPM)**, **Data Enablement**, and **Pharmacy Data Analysis**, I have collaborated closely with **cross-functional teams** to deliver business-ready datasets, optimize pipeline performance, and reduce project costs by approximately **20%** through efficient design and automation. I also have experience managing **CI/CD deployments using Azure DevOps** and working in **Agile delivery environments**.  
<br><br>

I am passionate about **continuous learning, performance optimization, and building robust cloud-native data ecosystems** that transform raw data into meaningful insights.  
<br>

---

### Tech Stack:
![C++](https://img.shields.io/badge/c++-%2300599C.svg?style=for-the-badge&logo=c%2B%2B&logoColor=white) ![Scala](https://img.shields.io/badge/scala-%23DC322F.svg?style=for-the-badge&logo=scala&logoColor=white) ![Apache Spark](https://img.shields.io/badge/Apache%20Spark-FDEE21?style=for-the-badge&logo=apachespark&logoColor=black) ![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54) ![CSS3](https://img.shields.io/badge/css3-%231572B6.svg?style=for-the-badge&logo=css3&logoColor=white) ![HTML5](https://img.shields.io/badge/html5-%23E34F26.svg?style=for-the-badge&logo=html5&logoColor=white) ![Azure](https://img.shields.io/badge/azure-%230072C6.svg?style=for-the-badge&logo=microsoftazure&logoColor=white) ![AWS](https://img.shields.io/badge/AWS-%23FF9900.svg?style=for-the-badge&logo=amazon-aws&logoColor=white) ![Oracle](https://img.shields.io/badge/Oracle-F80000?style=for-the-badge&logo=oracle&logoColor=white) ![Apache Kafka](https://img.shields.io/badge/Apache%20Kafka-000?style=for-the-badge&logo=apachekafka) ![Apache Hadoop](https://img.shields.io/badge/Apache%20Hadoop-66CCFF?style=for-the-badge&logo=apachehadoop&logoColor=black) ![Flask](https://img.shields.io/badge/flask-%23000.svg?style=for-the-badge&logo=flask&logoColor=white) ![NodeJS](https://img.shields.io/badge/node.js-6DA55F?style=for-the-badge&logo=node.js&logoColor=white) ![Snowflake](https://img.shields.io/badge/snowflake-%2329B5E8.svg?style=for-the-badge&logo=snowflake&logoColor=white) ![Apache Airflow](https://img.shields.io/badge/Apache%20Airflow-017CEE?style=for-the-badge&logo=Apache%20Airflow&logoColor=white) ![Jenkins](https://img.shields.io/badge/jenkins-%232C5263.svg?style=for-the-badge&logo=jenkins&logoColor=white) ![Apache](https://img.shields.io/badge/apache-%23D42029.svg?style=for-the-badge&logo=apache&logoColor=white) ![Apache Spark](https://img.shields.io/badge/Apache%20Spark-FDEE21?style=for-the-badge&logo=apachespark&logoColor=black) ![MySQL](https://img.shields.io/badge/mysql-4479A1.svg?style=for-the-badge&logo=mysql&logoColor=white) ![MicrosoftSQLServer](https://img.shields.io/badge/Microsoft%20SQL%20Server-CC2927?style=for-the-badge&logo=microsoft%20sql%20server&logoColor=white) ![NumPy](https://img.shields.io/badge/numpy-%23013243.svg?style=for-the-badge&logo=numpy&logoColor=white) ![Pandas](https://img.shields.io/badge/pandas-%23150458.svg?style=for-the-badge&logo=pandas&logoColor=white) ![scikit-learn](https://img.shields.io/badge/scikit--learn-%23F7931E.svg?style=for-the-badge&logo=scikit-learn&logoColor=white) ![Plotly](https://img.shields.io/badge/Plotly-%233F4F75.svg?style=for-the-badge&logo=plotly&logoColor=white) ![Matplotlib](https://img.shields.io/badge/Matplotlib-%23ffffff.svg?style=for-the-badge&logo=Matplotlib&logoColor=black) ![TensorFlow](https://img.shields.io/badge/TensorFlow-%23FF6F00.svg?style=for-the-badge&logo=TensorFlow&logoColor=white) ![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?style=for-the-badge&logo=PyTorch&logoColor=white) ![MySQL](https://img.shields.io/badge/mysql-4479A1.svg?style=for-the-badge&logo=mysql&logoColor=white) ![AWS](https://img.shields.io/badge/AWS-%23FF9900.svg?style=for-the-badge&logo=amazon-aws&logoColor=white) ![Azure](https://img.shields.io/badge/azure-%230072C6.svg?style=for-the-badge&logo=microsoftazure&logoColor=white) ![Anaconda](https://img.shields.io/badge/Anaconda-%2344A833.svg?style=for-the-badge&logo=anaconda&logoColor=white) ![Git](https://img.shields.io/badge/git-%23F05033.svg?style=for-the-badge&logo=git&logoColor=white) ![Docker](https://img.shields.io/badge/docker-%230db7ed.svg?style=for-the-badge&logo=docker&logoColor=white) ![Jira](https://img.shields.io/badge/jira-%230A0FFF.svg?style=for-the-badge&logo=jira&logoColor=white) ![Power Bi](https://img.shields.io/badge/power_bi-F2C811?style=for-the-badge&logo=powerbi&logoColor=black) ![Terraform](https://img.shields.io/badge/terraform-%235835CC.svg?style=for-the-badge&logo=terraform&logoColor=white)

---

## Experience:

### Project 1: Trade Price & Promotion Management (TPM)  
**Role:** Big Data Engineer  
**Organization:** TCS  
**Domain:** Retail | Pricing | Promotion Analytics  

**Key Contributions**
- Executed **end-to-end data migration** from **Mainframe and Teradata to Azure**, ensuring data accuracy and lineage.
- Configured **Power Apps** to ingest files into **Azure Delta Lake** for unified analytics.
- Authored and optimized **SQL stored procedures** with embedded business rules and data quality validations.
- Performed **data curation and transformation**, delivering clean, structured **CSV outputs**.
- Designed and automated **ADF-based ETL pipelines** using triggers and parameterized datasets.

---

### Project 2: Data Enablement  
**Role:** Big Data Engineer  
**Domain:** Enterprise Data Platforms  

**Key Contributions**
- Developed **JSON-based curation scripts** using **SQL and Spark SQL** under the **Curation V3 Framework**.
- Built **reusable SQL stored procedures** for standardized downstream consumption.
- Created preprocessing logic for converting **.txt to .csv**, enabling reuse across projects.
- Implemented large-scale **PySpark processing** and partitioning on **Azure Databricks**.
- Designed **incremental (accumulated) data loading** logic for scalable performance.
- Automated complete ETL lifecycle using **Azure Data Factory**.
- Managed CI/CD deployments via **Azure DevOps pipelines**.

---

### Project 3: Pharmacy Data Analysis  
**Role:** Big Data Engineer  
**Domain:** Healthcare | Analytics  

**Key Contributions**
- Designed and developed **scalable Spark applications** for cleansing, validation, transformation, and aggregation of **CSV, Parquet, and JSON** data.
- Engineered **ADF-based ETL pipelines** to ingest data into **ADLS Gen2**.
- Enabled **asset utilization analytics** and customer usage insights.
- Orchestrated **Databricks notebook jobs** using ADF triggers.
- Improved pipeline performance through **cluster tuning, caching, repartitioning, and modular code design**.

---

## Education

**Bachelor of Technology (B.Tech) – Electrical Engineering**  
**Cooch Behar Government Engineering College**  
*2017 – 2021*  
**CGPA:** 9.17  

**Higher Secondary Examination (WBCHSE)**  
Raipur Sri Sri Ramkrishna Amrita Vidyalaya  
*2017*  
**Percentage:** 78.8%  

**Secondary Examination (WBBSE)**  
Raipur Sri Sri Ramkrishna Amrita Vidyalaya  
*2015*  
**Percentage:** 76.85%  

---

## Certifications

- Microsoft Certified: Azure Fundamentals  
- Microsoft Certified: Azure Data Fundamentals  
- Microsoft Certified: Azure Administrator Associate  
- Microsoft Certified: Azure Data Engineer Associate  
- Databricks Lakehouse Fundamentals  
- Databricks Fundamentals  
- Databricks Generative AI Fundamentals  
- Databricks Certified Data Engineer Associate  
- Databricks Certified Professional Data Engineer Associate  

---

## GitHub Stats
![](https://github-readme-stats.vercel.app/api?username=bikrammondal&theme=dark&hide_border=false)<br/>
![](https://nirzak-streak-stats.vercel.app/?user=bikrammondal&theme=dark&hide_border=false)<br/>
![](https://github-readme-stats.vercel.app/api/top-langs/?username=bikrammondal&theme=dark&layout=compact)

---
[![](https://visitcount.itsvg.in/api?id=bikrammondal&icon=0&color=0)](https://visitcount.itsvg.in)
